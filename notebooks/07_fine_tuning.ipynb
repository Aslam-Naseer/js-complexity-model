{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6a04d1",
   "metadata": {},
   "source": [
    "## Fine Tuning\n",
    "\n",
    "Assuming running on T4 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c1ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "%pip install -q --upgrade bitsandbytes==0.48.2 trl==0.25.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b11d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "from google.colab import userdata\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "import wandb\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceb1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "MODEL = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "PROJECT_NAME = \"complexity\"\n",
    "HF_USER = \"aslam-naseer\"\n",
    "\n",
    "DATA_USER = \"aslam-naseer\"\n",
    "DATASET_NAME = f\"{DATA_USER}/js-function-complexity-messages\"\n",
    "\n",
    "RUN_NAME =  f\"{datetime.now():%Y-%m-%d_%H.%M.%S}\"\n",
    "PROJECT_RUN_NAME = f\"{PROJECT_NAME}-{RUN_NAME}\"\n",
    "HUB_MODEL_NAME = f\"{HF_USER}/{PROJECT_RUN_NAME}\"\n",
    "\n",
    "# Hyper-parameters - overall\n",
    "\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 1\n",
    "MAX_SEQUENCE_LENGTH = 3072\n",
    "GRADIENT_ACCUMULATION_STEPS = 16\n",
    "\n",
    "# Hyper-parameters - QLoRA\n",
    "\n",
    "QUANT_4_BIT = True\n",
    "LORA_R = 32\n",
    "LORA_ALPHA = 16\n",
    "TARGET_MODULES = \"all-linear\"\n",
    "LORA_DROPOUT = 0.05\n",
    "\n",
    "# Hyper-parameters - training\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "WARMUP_RATIO = 0.03\n",
    "LR_SCHEDULER_TYPE = 'cosine'\n",
    "WEIGHT_DECAY = 0.001\n",
    "OPTIMIZER = \"paged_adamw_32bit\"\n",
    "\n",
    "capability = torch.cuda.get_device_capability()\n",
    "use_bf16 = capability[0] >= 8\n",
    "\n",
    "# Tracking\n",
    "\n",
    "LOG_STEPS = 5\n",
    "SAVE_STEPS = 100\n",
    "LOG_TO_WANDB = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41233156",
   "metadata": {},
   "source": [
    "#### Load API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12df706",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = userdata.get(\"HF_TOKEN\")\n",
    "if not hf_token:\n",
    "    raise ValueError(\"HF_TOKEN not found in environment variables.\")\n",
    "\n",
    "login(hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e323ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_api_key = userdata.get('WANDB_API_KEY')\n",
    "if not wandb_api_key:\n",
    "    raise ValueError(\"WANDB_API_KEY not found in environment variables.\")\n",
    "os.environ[\"WANDB_API_KEY\"] = wandb_api_key\n",
    "\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"false\"\n",
    "os.environ[\"WANDB_WATCH\"] = \"false\"\n",
    "os.environ[\"WANDB_ENTITY\"] = \"aslam-naseer-personal\"\n",
    "\n",
    "wandb.login()\n",
    "if LOG_TO_WANDB:\n",
    "    wandb.init(project=PROJECT_NAME, name=RUN_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7945dd97",
   "metadata": {},
   "source": [
    "### Load dataset and config objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53694633",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(DATASET_NAME)\n",
    "\n",
    "train = dataset['train']\n",
    "val = dataset['validation']\n",
    "test = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79aced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUANT_4_BIT:\n",
    "  quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16 if use_bf16 else torch.float16\n",
    "    bnb_4bit_quant_type='nf4'\n",
    "  )\n",
    "\n",
    "else:\n",
    "  quant_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16 if use_bf16 else torch.float16\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c447294",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    quantization_config=quant_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\" if use_bf16 else \"eager\", \n",
    ")\n",
    "\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "print(f\"Memory footprint: {model.get_memory_footprint() / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ce0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "  r=LORA_R,\n",
    "  lora_alpha=LORA_ALPHA,\n",
    "  target_modules=TARGET_MODULES,\n",
    "  lora_dropout=LORA_DROPOUT,\n",
    "  bias=\"none\",\n",
    "  task_type=\"CAUSAL_LM\",\n",
    "  use_rslora=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417472b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_config = SFTConfig(\n",
    "    output_dir=PROJECT_RUN_NAME,\n",
    "    num_train_epochs=EPOCHS,\n",
    "\n",
    "    max_length=MAX_SEQUENCE_LENGTH,\n",
    "    packing=False,\n",
    "    group_by_length=True,\n",
    "\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "\n",
    "    optim=OPTIMIZER,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    save_total_limit=3,\n",
    "    logging_steps=LOG_STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.001,\n",
    "    fp16=not use_bf16,\n",
    "    bf16=use_bf16,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
    "\n",
    "    report_to=\"wandb\" if LOG_TO_WANDB else None,\n",
    "    run_name=RUN_NAME,\n",
    "\n",
    "    save_strategy=\"steps\",\n",
    "    hub_strategy=\"every_save\",\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=HUB_MODEL_NAME,\n",
    "    hub_private_repo=True,\n",
    "\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=SAVE_STEPS,\n",
    "\n",
    "    dataset_kwargs={\n",
    "        \"append_concat_token\": False,\n",
    "        \"add_special_tokens\": False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3713da2f",
   "metadata": {},
   "source": [
    "### Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26041fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning = SFTTrainer(\n",
    "  model=model,\n",
    "  tokenizer=tokenizer,\n",
    "  train_dataset=train,\n",
    "  eval_dataset=val,\n",
    "  peft_config=lora_config,\n",
    "  args=sft_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f5011",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning.train()\n",
    "\n",
    "fine_tuning.model.push_to_hub(PROJECT_RUN_NAME, private=True)\n",
    "print(f\"Saved to the hub: {PROJECT_RUN_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aa2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOG_TO_WANDB:\n",
    "  wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "js-complexity-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
